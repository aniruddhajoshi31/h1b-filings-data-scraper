# H1B Filings Scraper

This tool scrapes data from [h1bdata.info](https://h1bdata.info/), presenting the number of H1B filings by various companies based on user inputs.

NOTE/CAUTION: This is code can break, and I created it knowing what I wanted from it. If you want it to be robust and handle all the edge cases, you can go ahead. 

## Table of Contents

- [Description](#description)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

## Description

Using the script, you can search for H1B filings based on specific criteria: 
- Employer Name
- Job/Position Title
- City
- Year

The results are displayed in a sorted list, showing companies and the number of their respective H1B filings in descending order.

## Features

- User-friendly interface that takes custom search parameters.
- Data scraping from a reliable online resource.
- Output displayed as a table, sorted based on the count of H1B filings.

## Installation

```
# Clone the Repository
git clone https://github.com/aniruddhajoshi31/h1b-filings-data-scraper

# Navigate to the Directory
cd h1b-filings-data-scraper

# Install Required Python Libraries
pip install -r requirements.txt
```
## Usage

After installation, you can run the Jupyter Notebook and follow the interactive prompts to input your search criteria.

## Contributing

If you wish to contribute to this project:

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/YourFeatureName`)
3. Commit your changes (`git commit -m 'Add a feature'`)
4. Push to the branch (`git push origin feature/YourFeatureName`)
5. Open a pull request

## License

This project is open source and available to anyone under the [MIT License](LICENSE).


